# Pandas

# Pandas란?

정형 데이터에 대하여 데이터 조작 및 분석을 수행할 때 주로 쓰이는 파이썬 라이브러리다. 특히, 숫자 테이블 및 시계열 데이터를 위한 데이터 구조 및 함수를 제공한다.

속도가 느려서 polars, modin-pandas(분산 병렬 처리) 등의 라이브러리를 쓰기도 한다.

Pandas는 내부적으로 Numpy를 포함한다.

# Series

Series는 Pandas의 대표적인 데이터 객체 표현으로서, 라벨(컬럼 이름)을 가진 1차원 배열이다. 

Pandas는 내부적으로 Numpy를 포함하고 있기 때문에, Numpy의 데이터 타입을 그대로 가져가며, Series는 Numpy의 column vector와 동일하다.

$Series\ = {\begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ ... \\ x_n \end{bmatrix}}$

```python
S = pd.Series(np.array([1, 2, 3, 4, 5, 6, 7, 8]), name='변수 이름')
S
```

```python
0    1
1    2
2    3
3    4
4    5
5    6
6    7
7    8
Name: 변수 이름, dtype: int64
```

# DataFrame

데이터 프레임(DataFrame)은 엑셀 시트처럼 행 index와 컬럼을 가진 2차원 배열로서, Pandas의 대표적인 데이터 객체 표현이다.

$DataFrame\ = {\begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ ... \\ x_n \end{bmatrix}}  {\begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ ... \\ x_n \end{bmatrix}} {\begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ ... \\ x_n \end{bmatrix}}$

```python
DF = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]], columns=['Var1', 'Var2', 'Var3'])
DF
```

![Untitled](Pandas%205162fb14aa874a739b7fd03f87a99af7/Untitled.png)

# Pandas의 주요 함수 및 기능

## `read_csv()`

```python
pd.read_csv(파일명)
```

csv(comma-separated variables) 파일로 이루어진 데이터를 DataFrame으로 변환하여 읽어온다.

read_csv 이외에도 read_excel, read_sql, read_json, read_html, read_parquet, read_pickle, read_clipboard 등이 있다.

주로 정형 데이터를 읽어올 때 사용된다.

```python
# from google.colab import drive
# drive.mount('/content/drive')

from os.path import join
from pathlib import Path

BASE_DIR = Path('/content/drive/MyDrive') # Path와 join은 운영체제마다 다른 경로체계를 쉽게 지정할 수 있게 한다.

filename = join(BASE_DIR, './data', 'sample_adult_data.csv')
DF = pd.read_csv(filename)

DF
```

![Untitled](Pandas%205162fb14aa874a739b7fd03f87a99af7/Untitled%201.png)

## `head()`, `tail()`

첫 n줄, 끝 n줄을 읽는다.

## **`DataFrame.shape`**

Numpy의 `np.shape`처럼 차원을 확인할 수 있는 속성

차원을 변경할 수 있는 reshape 함수는 따로 존재하지 않는다. 차원을 변경하고자 한다면, Numpy로 변환한 후에 np.reshape으로 차원 변경 후 다시 Pandas DataFrame으로 변환해야 한다.

```python
DF.shape

# (48842, 15)
```

## `info()`

Series나 DataFrame 객체가 가진 변수들의 정보를 보여준다.

변수들의 자료형(수치형 or 범주형)을 확인하기 위해 사용한다.

```python
DF.info()
```

```python
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 48842 entries, 0 to 48841
Data columns (total 15 columns):
 #   Column          Non-Null Count  Dtype 
---  ------          --------------  ----- 
 0   age             48842 non-null  int64 
 1   workclass       48842 non-null  object
 2   fnlwgt          48842 non-null  int64 
 3   education       48842 non-null  object
 4   education-num   48842 non-null  int64 
 5   marital-status  48842 non-null  object
 6   occupation      48842 non-null  object
 7   relationship    48842 non-null  object
 8   race            48842 non-null  object
 9   sex             48842 non-null  object
 10  capital-gain    48842 non-null  int64 
 11  capital-loss    48842 non-null  int64 
 12  hours-per-week  48842 non-null  int64 
 13  native-country  48842 non-null  object
 14  income          48842 non-null  object
dtypes: int64(6), object(9)
memory usage: 5.6+ MB
```

DataFrame의 각 열에 대한 정보를 제공하며, 각 열의 데이터 유형(dtype), 비어 있지 않은 값의 개수, 메모리 사용량 등을 보여준다.

실제로 데이터가 비어 있는지 여부를 확인하려면 추가적인 탐색(EDA)이 필요하다. 데이터 내에 `?`,  ``, `x` 등으로 표시된 것들이 있을 수 있기 때문인데, 이런 것들은 non-null로 감지되지 않기 때문이다. Null값 여부는 직접 EDA를 통해 확인해야 한다.

object라 표시된 것들은 대부분이 범주형 데이터이며, 때로는 문자열 데이터를 나타낼 수도 있다.

## `describe()`

Series나 DataFrame 객체의 각 변수(열)에 대한 기초 통계량을 요약하여 출력한다. 이를 통해 데이터의 분포와 중요한 특성을 파악할 수 있다.

- 수치형 변수의 경우: 최대, 최소, 중간, 평균, 표준편차
- 범주형 변수의 경우: 범주의 수, 최빈값, 최빈값의 빈도수

```python
DF.describe()
```

![Untitled](Pandas%205162fb14aa874a739b7fd03f87a99af7/Untitled%202.png)

describe를 보면서, 데이터의 분포나 이상치 등을 파악하여 데이터 전처리에 대한 결정을 내려야 한다. 예를 들어, 평균값이 이상하다면 분포 모양이 이상할 것이라는 추론이 가능하며, 이 추론을 통해 어떻게 해당 데이터를 전처리할지를 결정해야 한다.

```python
DF.describe(include='all')
```

![Untitled](Pandas%205162fb14aa874a739b7fd03f87a99af7/Untitled%203.png)

include=’all’ 옵션을 통해, 범주형 데이터까지 포함한 기초 통계량 정보를 얻을 수 있다.

한 가지 주의할 점은 데이터의 특성에 따라 이러한 통계량이 해석이 다를 수 있으며, 모든 상황에서 해당 통계량이 항상 해결책을 제시하는 것은 아니다. 따라서, 데이터의 도메인 지식과 추가적인 분석이 필요할 수 있다는 점을 유념한다.

## `values`

Series나 DataFrame에서 값을 Numpy 배열(ndarray)로 반환해준다. 이는 데이터프레임에서 Pandas의 자체 연산을 수행할 때보다 더 빠르게 연산을 수행할 수 있도록 도와준다.

이를 보완하기 위한 대안은 다음과 같다.

- Pandas의 apply를 사용한다.
- Pandas의 map을 사용한다.
- Numpy 배열로 변환하여 사용한다. (일반적으로, Numpy가 Pandas보다 더 빠르기 때문에.)

```python
DF.values
```

```
array([[39, ' State-gov', 77516, ..., 40, ' United-States', '<=50K'],
       [50, ' Self-emp-not-inc', 83311, ..., 13, ' United-States',
        '<=50K'],
       [38, ' Private', 215646, ..., 40, ' United-States', '<=50K'],
       ...,
       [38, ' Private', 374983, ..., 50, ' United-States', '<=50K'],
       [44, ' Private', 83891, ..., 40, ' United-States', '<=50K'],
       [35, ' Self-emp-inc', 182148, ..., 60, ' United-States', '>50K']],
      dtype=object)
```

## `concat()`

지정한 축 정보를 기반으로 Pandas 객체를 서로 연결한다. **`axis=0`**은 행(row)을 따라 연결하고, **`axis=1`**은 열(column)을 따라 연결한다.

```python
DF.shape 
# (48842, 15)
```

```python
pd.concat([DF, DF], axis=0).shape
# (97684, 15)
```

```python
pd.concat([DF, DF], axis=1).shape
# (48842, 30)
```

행(axis=0)을 따라 연결하면 행의 수가 두 배가 되고, 열(axis=1)을 따라 연결하면 열의 수가 두 배가 된 결과를 확인할 수 있다.

## DataFrame에 대한 필터링 1

특정 조건에 맞는 행, 열을 추출하는 작업을 말한다. 라벨(label) 기반 인덱싱을 사용하며, 행과 열을 지정할 수 있다.

### `loc[]`

```python
DataFrame.loc[행 조건, 열 조건 또는 열 리스트]
```

행 조건과 열 조건에 맞는 행과 열을 찾는다.

```python
DF['age'] == 39
```

```
0         True
1        False
2        False
3        False
4        False
         ...
48837     True
48838    False
48839    False
48840    False
48841    False
Name: age, Length: 48842, dtype: bool
```

행 조건만을 제시할 수 있으며, 위 예제는 age가 ‘39’인 데이터를 필터링한다.

---

```python
filter_columns = ['age', 'workclass', 'fnlwgt', 'education', 'marital-status']
DF.loc[DF['age'] == 39, filter_columns]
```

열 조건으로 'age, workclass, fnlwgt, education, marital-status' 열로 구성된 데이터를, 행 조건으로 age가 ‘39’인 데이터를 추출한다.

### `iloc[]`

```python
DataFrame.iloc[행 인덱스, 열 인덱스]
```

인덱스에 맞는 행과 열을 선택한다. 즉, 인덱스 값 자체를 기반으로 선택하는 것이 아니라 위치를 기반으로 값을 선택한다.

```python
DF.iloc[[0,2,4,6,8], [1,3,5,7,9]] 
```

![Untitled](Pandas%205162fb14aa874a739b7fd03f87a99af7/Untitled%204.png)

이 코드는 0, 2, 4, 6, 8번째 행과 1, 3, 5, 7, 9번째 열을 선택한다.

## DataFrame에 대한 필터링 2

### `map()`

```python
 DataFrame[**specific_column_name**].map(실행하고 싶은 함수식:람다함수도 가능)
```

`map` 함수는 Pandas Series에 사용할 수 있는 함수로서, Series의 각 원소에 연산을 적용한 후 단일 값을 리턴받는다.

```python
DF['age'].hist(bins=50)
```

![Untitled](Pandas%205162fb14aa874a739b7fd03f87a99af7/Untitled%205.png)

예를 들어, age 컬럼의 분포를 보았더니 한 쪽으로 치우친 것을 볼 수 있다. 따라서 log를 적용하여 값을 보정해보고 싶다고 해보자.

```python
DF['log_age'] = DF['age'].map(lambda x: np.log(x))
# age에 log 연산을 취한다.
DF['age'].hist(bins=50)
```

![Untitled](Pandas%205162fb14aa874a739b7fd03f87a99af7/Untitled%206.png)

그래프를 보면, log를 취하기 전에 비해 그래프가 상대적으로 조금 더 대칭을 이루는 것으로 나온다.

이와 같이, 단일 컬럼의 각 원소에 대해 연산을 적용할 땐 map을 사용한다.

### `apply()`

DataFrame의 행 또는 열에 대해 함수를 적용하여 연산을 수행하는 데 사용된다. 특정 축(`axis=0` 또는 `axis=1`)에 대해 연산을 적용할 수 있다.

<aside>
💡 axis=1 연산을 주로 사용한다. DataFrame 자체가 행이 아닌 열 위주의 구성이기 때문이다.

</aside>

```python
DF['sum_num_var'] = DF.apply(lambda x: sum([value for value in x if isinstance(value, (int, float))]),
                             axis=1)
DF['sum_num_var']
```

```
0         79785.663562
1         83390.912023
2        215736.637586
3        234824.970292
4        338493.332205
             ...
48837    215510.663562
48838    321520.158883
48839    375087.637586
48840     89446.784190
48841    182259.555348
Name: sum_num_var, Length: 48842, dtype: float64
```

각 행에 대해 lambda 함수를 사용하여 수치형(`int`형 또는 `float`형) 열 값의 합을 계산하기 위하여 위 코드와 같이 사용자 지정 함수를 적용할 수 있다. 이결과를 새로운 열인 **`sum_num_var`**에 할당한다.

<aside>
💡 위와 같이 새로운 열을 만드는 것도 feature engineering의 일종이라고 볼 수 있다.

</aside>

### `applymap()`

DataFrame의 모든 원소에 함수를 적용하는 데 사용된다. 각각의 원소에 대해 사용자가 정의한 함수나 람다 함수를 적용할 수 있다. Series의 **`map()`** 메서드와는 다르지만, Series의 **`map()`**과 동일한 기능을 수행한다. 이는 DataFrame의 각 요소에 대해 함수를 적용하는 것이 아니라, DataFrame의 각 열을 Series로 간주하여 각 Series의 요소에 함수를 적용하고 있기 때문이다.

Series의 map과 동일하게 각 원소에 사용자 정의 함수 등의 연산을 적용한다.

```python
DF.applymap(lambda x: np.log1p(x) if isinstance(x, (int, float)) else x)
```

![Untitled](Pandas%205162fb14aa874a739b7fd03f87a99af7/Untitled%207.png)

## `reset_index()`

DataFrame의 현재 인덱스를 재설정하여 새로운 숫자로 된 인덱스로 변경합니다. 기존의 인덱스는 새로운 열로 추가되며, 메서드는 새로운 DataFrame을 반환합니다.

즉, 기존의 인덱스를 새로운 열로 추가하며, 기존 인덱스는 숫자로 된 새로운 인덱스로 대체시킨다.

```python
sample_DF = DF.sample(5)
print(sample_DF)
print(sample_DF.index)
```

![Untitled](Pandas%205162fb14aa874a739b7fd03f87a99af7/Untitled%208.png)

```python
Int64Index([46484, 4278, 47706, 625, 43590], dtype='int64')
```

데이터를 Pandas로 불러오면 보통 index가 위와 같이 엉망이 되어 있다.

```python
reset_sample_DF = sample_DF.reset_index()
print(reset_sample_DF)
```

![Untitled](Pandas%205162fb14aa874a739b7fd03f87a99af7/Untitled%209.png)

이를 reset_index()를 이용하면 위와 같이 새로운 인덱스가 부여되고, 기존의 index는 세로운 컬럼으로 추가된다.

## `drop`

```python
sample_DF.reset_index(drop=True)
```

![Untitled](Pandas%205162fb14aa874a739b7fd03f87a99af7/Untitled%2010.png)

drop 옵션을 True로 설정하면 기존의 인덱스를 새로운 열로 추가하지 않는다. 

## inplace

일반적으로 Pandas 함수들은 연산 후 연산이 적용된 새로운 객체를 생성해서 반환하지만, inplace를 쓰면 그대로 내부에서 연산을 하여 원본을 바꾸고 객체를 반환하지않는다.

DataFrame은 원본을 바꾸면 롤백이 불가능하지만, 원본에 재할당해서 쓸 수 있는 옵션이 있다. 

앞선 [예제 코드](https://www.notion.so/Pandas-5162fb14aa874a739b7fd03f87a99af7?pvs=21)에서는 drop을 적용한 결과를 리턴받았어야 하지만 그러지 않았다. 원본 자체를 바꾸고자 한다면 아래와 같은 코드를 쓴다.

```python
sample_DF.reset_index(inplace=True, drop=True) 
```

위와 같이 작성하면 None이 리턴되면서 sample_DF 원본에 바로 적용된다.

![Untitled](Pandas%205162fb14aa874a739b7fd03f87a99af7/Untitled%2011.png)

## `groupby()`

graoupby()는 주어진 열(또는 열의 리스트)을 기준으로 DataFrame을 그룹화하여 그룹별로 연산을 수행하고 새로운 결과 값을 가진 DataFrame을 반환한다.

`groupby()`는 특정 컬럼을 index로 하여 새로운 결과값을 가진 DataFrame을 반환하는 연산 메서드다. 

```python
workclass_DF = sample_DF.groupby(by='workclass').mean()
workclass_DF
```

![Untitled](Pandas%205162fb14aa874a739b7fd03f87a99af7/Untitled%2012.png)

`by` 파라미터는 단일 값 또는 리스트를 받을 수 있다. 이를 통해 단일 열 또는 여러 열을 기준으로 그룹화할 수 있다.

위 코드는 'workclass' 열을 기준으로 그룹화한 후 각 그룹에 대한 평균을 계산한 결과를 보여준다.

`groupby()`에 사용한 `by` 파라미터의 값인 ‘workclass’가 index로 설정된 것을 해지하려면 `reset_index()` 메서드를 사용하여 그룹화된 결과의 인덱스를 기본 정수 인덱스로 다시 설정한다. 이를 통해 기존에 인덱스로 설정된 열을 데이터프레임의 새로운 열로 다시 추가할 수 있다.

```python
workclass_DF = sample_DF.groupby(by='workclass').mean().reset_index()
workclass_DF
```

![Untitled](Pandas%205162fb14aa874a739b7fd03f87a99af7/Untitled%2013.png)

## `join()`

두 개 이상의 DataFrame을 특정 열(또는 인덱스)을 기준으로 결합하는 기능을 제공한다. 이를 통해 데이터를 조합하거나 병합할 수 있다. 

매개변수는 다음과 같다.

- `other`: 결합할 대상이 되는 DataFrame 객체
- `on`: 결합할 때 사용할 열의 이름 (기본값: `None`).
- `how`: 결합 방법 (가능한 값: `'left'`, `'right'`, `'outer'`, `'inner'`)

```python
import pandas as pd

# 첫 번째 DataFrame 생성
df1 = pd.DataFrame({'key': ['A', 'B', 'C', 'D'],
                    'value': [1, 2, 3, 4]})

# 두 번째 DataFrame 생성
df2 = pd.DataFrame({'key': ['B', 'D', 'E', 'F'],
                    'value': [5, 6, 7, 8]})

# 'key' 열을 기준으로 두 DataFrame을 결합
result = df1.join(df2.set_index('key'), on='key', lsuffix='_left', rsuffix='_right')

print(result)
```

```python
  key  value_left  value_right
0   A           1          NaN
1   B           2          5.0
2   C           3          NaN
3   D           4          6.0

```

# 브로드캐스팅

Numpy와 마찬가지로 Pandas도 브로드캐스팅 기능이 있다. Numpy와 마찬가지로 Pandas에서도 브로드캐스팅 기능은 차원에 맞게 연산이 알아서 적용되는 것을 말한다.

```python
A = np.random.randint(2, 10, size=(4, 5))
A

# array([[8, 5, 6, 2, 7],
#        [4, 3, 5, 4, 5],
#        [6, 7, 5, 2, 9],
#        [6, 7, 5, 6, 9]])
```

```python
np.log(A)

# array([[2.07944154, 1.60943791, 1.79175947, 0.69314718, 1.94591015],
#        [1.38629436, 1.09861229, 1.60943791, 1.38629436, 1.60943791],
#        [1.79175947, 1.94591015, 1.60943791, 0.69314718, 2.19722458],
#        [1.79175947, 1.94591015, 1.60943791, 1.79175947, 2.19722458]])
```

# LeetCode 문제풀이