# ë°ì´í„° ì „ì²˜ë¦¬

ë°ì´í„° ì „ì²˜ë¦¬ëŠ” ëª¨ë¸ í•™ìŠµ ì „ì— ìˆ˜í–‰ëœë‹¤.

# EDA

```python
import os
from os.path import join
from pathlib import Path
import copy
import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd

# from google.colab import drive
# drive.mount('/content/drive')

ROOT_PATH = Path('/content/drive/MyDrive/data')
example_file = join(ROOT_PATH, 'Hospital', 'train.csv')

data = pd.read_csv(example_file)
data.head()
```

ì‚¬ìš©í•˜ê³ ì í•˜ëŠ” ë°ì´í„°ëŠ” Hospital ë°ì´í„°ë¡œì„œ, imbalanced dataë‹¤. 

```
train.csvÂ -Â ì˜ë£Œê¸°ê´€ì´Â íì—…í–ˆëŠ”ì§€Â ì—¬ë¶€ë¥¼Â í¬í•¨í•˜ì—¬Â ìµœê·¼Â 2ê°œë…„ì˜Â ì¬ë¬´ì •ë³´ì™€Â ë³‘ì›Â ê¸°ë³¸ì •ë³´
test.csvÂ -Â íì—…Â ì—¬ë¶€ë¥¼Â ì œì™¸í•˜ê³ Â train.csvì™€Â ë™ì¼
sample_submission.csvÂ -Â inst_idì™€Â openê³¼Â closeë¥¼Â ì˜ˆì¸¡í•˜ëŠ”Â OCÂ ë‘ê°œì˜Â ì—´ë¡œÂ êµ¬ì„±.Â OCì˜Â ê°’ì€Â openÂ ì˜ˆì¸¡ì¼Â ê²½ìš°Â 1,Â closeÂ ì˜ˆì¸¡ì¼Â ê²½ìš°Â 0.

inst_idÂ -Â ê°Â íŒŒì¼ì—ì„œì˜Â ë³‘ì›Â ê³ ìœ Â ë²ˆí˜¸
OCÂ â€“Â ì˜ì—…/íì—…Â ë¶„ë¥˜,Â 2018ë…„Â íì—…ì€Â 2017ë…„Â íì—…ìœ¼ë¡œÂ ê°„ì£¼í•¨
sidoÂ â€“Â ë³‘ì›ì˜Â ê´‘ì—­Â ì§€ì—­Â ì •ë³´
sggÂ â€“Â ë³‘ì›ì˜Â ì‹œêµ°êµ¬Â ìë£Œ
openDateÂ â€“Â ë³‘ì›Â ì„¤ë¦½ì¼
bedCountÂ -Â ë³‘ì›ì´Â ê°–ì¶”ê³ Â ìˆëŠ”Â ë³‘ìƒì˜Â ìˆ˜
instkindÂ â€“Â ë³‘ì›,Â ì˜ì›,Â ìš”ì–‘ë³‘ì›,Â í•œì˜ì›,Â ì¢…í•©ë³‘ì›Â ë“±Â ë³‘ì›ì˜Â ì¢…ë¥˜
Â·Â Â Â Â Â Â Â Â ì¢…í•©ë³‘ì›Â :Â ì…ì›í™˜ìÂ 100ëª…Â ì´ìƒÂ ìˆ˜ìš©Â ê°€ëŠ¥
Â·Â Â Â Â Â Â Â Â ë³‘ì›Â :Â ì…ì›Â í™˜ìÂ 30ëª…Â ì´ìƒÂ 100ëª…Â ë¯¸ë§ŒÂ ìˆ˜ìš©Â ê°€ëŠ¥
Â·Â Â Â Â Â Â Â Â ì˜ì›Â :Â ì…ì›Â í™˜ìÂ 30ëª…Â ì´í•˜Â ìˆ˜ìš©Â ê°€ëŠ¥
Â·Â Â Â Â Â Â Â Â í•œë°©Â ë³‘ì›(í•œì˜ì›)Â :Â ì¹¨ìˆ ê³¼Â í•œì•½ìœ¼ë¡œÂ ì¹˜ë£Œí•˜ëŠ”Â ì˜ë£ŒÂ ê¸°ê´€.
revenue1Â â€“Â ë§¤ì¶œì•¡,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
salescost1Â â€“Â ë§¤ì¶œì›ê°€,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
sga1Â -Â íŒë§¤ë¹„ì™€Â ê´€ë¦¬ë¹„,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
salary1Â â€“Â ê¸‰ì—¬,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
noi1Â â€“Â ì˜ì—…ì™¸ìˆ˜ìµ,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
noe1Â â€“Â ì˜ì—…ì™¸ë¹„ìš©,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
Interest1Â â€“Â ì´ìë¹„ìš©,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
ctax1Â â€“Â ë²•ì¸ì„¸ë¹„ìš©,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
Profit1Â â€“Â ë‹¹ê¸°ìˆœì´ìµ,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
liquidAsset1Â â€“Â ìœ ë™ìì‚°,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
quickAsset1Â â€“Â ë‹¹ì¢Œìì‚°,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
receivableS1Â -Â ë¯¸ìˆ˜ê¸ˆ(ë‹¨ê¸°),Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
inventoryAsset1Â â€“Â ì¬ê³ ìì‚°,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
nonCAsset1Â â€“Â ë¹„ìœ ë™ìì‚°,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
tanAsset1Â â€“Â ìœ í˜•ìì‚°,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
OnonCAsset1Â -Â ê¸°íƒ€Â ë¹„ìœ ë™ìì‚°,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
receivableL1Â â€“Â ì¥ê¸°ë¯¸ìˆ˜ê¸ˆ,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
debt1Â â€“Â ë¶€ì±„ì´ê³„,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
liquidLiabilities1Â â€“Â ìœ ë™ë¶€ì±„,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
shortLoan1Â â€“Â ë‹¨ê¸°ì°¨ì…ê¸ˆ,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
NCLiabilities1Â â€“Â ë¹„ìœ ë™ë¶€ì±„,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
longLoan1Â â€“Â ì¥ê¸°ì°¨ì…ê¸ˆ,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
netAsset1Â â€“Â ìˆœìì‚°ì´ê³„,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
surplus1Â â€“Â ì´ìµì‰ì—¬ê¸ˆ,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
revenue2Â â€“Â ë§¤ì¶œì•¡,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
salescost2Â â€“Â ë§¤ì¶œì›ê°€,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
sga2Â -Â íŒë§¤ë¹„ì™€Â ê´€ë¦¬ë¹„,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
salary2Â â€“Â ê¸‰ì—¬,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
noi2Â â€“Â ì˜ì—…ì™¸ìˆ˜ìµ,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
noe2Â â€“Â ì˜ì—…ì™¸ë¹„ìš©,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
interest2Â â€“Â ì´ìë¹„ìš©,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
ctax2Â â€“Â ë²•ì¸ì„¸ë¹„ìš©,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
profit2Â â€“Â ë‹¹ê¸°ìˆœì´ìµ,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
liquidAsset2Â â€“Â ìœ ë™ìì‚°,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
quickAsset2Â â€“Â ë‹¹ì¢Œìì‚°,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
receivableS2Â -Â ë¯¸ìˆ˜ê¸ˆ(ë‹¨ê¸°),Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
inventoryAsset2Â â€“Â ì¬ê³ ìì‚°,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
nonCAsset2Â â€“Â ë¹„ìœ ë™ìì‚°,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
tanAsset2Â â€“Â ìœ í˜•ìì‚°,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
OnonCAsset2Â -Â ê¸°íƒ€Â ë¹„ìœ ë™ìì‚°,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
receivableL2Â â€“Â ì¥ê¸°ë¯¸ìˆ˜ê¸ˆ,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
Debt2Â â€“Â ë¶€ì±„ì´ê³„,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
liquidLiabilities2Â â€“Â ìœ ë™ë¶€ì±„,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
shortLoan2Â â€“Â ë‹¨ê¸°ì°¨ì…ê¸ˆ,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
NCLiabilities2Â â€“Â ë¹„ìœ ë™ë¶€ì±„,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
longLoan2Â â€“Â ì¥ê¸°ì°¨ì…ê¸ˆ,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
netAsset2Â â€“Â ìˆœìì‚°ì´ê³„,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
surplus2Â â€“Â ì´ìµì‰ì—¬ê¸ˆ,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
employee1Â â€“Â ê³ ìš©í•œÂ ì´Â ì§ì›ì˜Â ìˆ˜,Â 2017(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
employee2Â â€“Â ê³ ìš©í•œÂ ì´Â ì§ì›ì˜Â ìˆ˜,Â 2016(íšŒê³„ë…„ë„)ë…„Â ë°ì´í„°ë¥¼Â ì˜ë¯¸í•¨
ownerChangeÂ â€“Â ëŒ€í‘œìì˜Â ë³€ë™
```

## ëª¨ë“  column ë³´ê¸°

`head()` ë©”ì„œë“œë§Œìœ¼ë¡œëŠ” jupyter notebook ë“±ì˜ IDEì—ì„œ ëª¨ë“  ì»¬ëŸ¼ì„ í™•ì¸í•  ìˆ˜ ì—†ë‹¤. `set_option()`ì„ ì‚¬ìš©í•˜ë©´ ëª¨ë“  ì»¬ëŸ¼ì„ ë³¼ ìˆ˜ ìˆë‹¤.

```python
pd.set_option('display.max_rows',500)
pd.set_option('display.max_columns',500)
data.head()
```

---

```python
data.shape # (301, 58)
```

## ë°ì´í„° ì „ì²˜ë¦¬

ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ê¸° ìœ„í•´ì„œëŠ” ê° featureê°€ ì˜ë¯¸í•˜ëŠ” ë°”ë¥¼ ì¼ì¼ì´ íŒŒì•…í•´ì•¼ í•œë‹¤. ì´ ê³¼ì •ì—ëŠ” ë„ë©”ì¸ ì§€ì‹ì´ í•„ìš”í•˜ë‹¤.

ë˜í•œ ì–´ëŠ í•œ featureê°€ ë‹¤ë¥¸ featureì™€ ì—°ê´€ì„ ê°€ì§ˆ ìˆ˜ë„ ìˆê¸° ë•Œë¬¸ì— feature engineering ë“±ì„ ìˆ˜í–‰í•´ì•¼ í•œë‹¤.

## NaNê°’ ì—¬ë¶€ í™•ì¸

![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled.png)

ì´ ë°ì´í„°ëŠ” SQLì„ ì´ìš©í•˜ì—¬ outer joinì´ ì¼ì–´ë‚œ ê²°ê³¼ë¬¼ë¡œ ì¶”ì •ëœë‹¤. ì´ NaN ê°’ë“¤ì„ ì–´ë–»ê²Œ ì±„ì›Œì•¼ í• ê¹Œ?

## ë¼ë²¨ì˜ êµ¬ë¶„

í˜„ì¬ ì´ ë°ì´í„°ì—ì„œ ë¼ë²¨ì€ `OC` ì»¬ëŸ¼ìœ¼ë¡œì„œ, ë³‘ì›ì˜ ê°œ/íì—… ìœ ë¬´ë‹¤.

ë¼ë²¨ì€ ì•„ë˜ì™€ ê°™ì´ ë³„ë„ë¡œ êµ¬ë¶„í•˜ëŠ” ê²Œ ì¢‹ë‹¤.

```python
label = data['OC']
```

ê·¸ë¦¬ê³  ë°ì´í„°ì— ìˆëŠ” ë¼ë²¨ ì»¬ëŸ¼ì„ ì œê±°í•´ì•¼ í•œë‹¤. `del` ë˜ëŠ” `drop()`ì„ ì“´ë‹¤.

```python
# del data['OC']
data.drop(columns=['OC'], inplace=True)
```

## describe()

ê° ë³€ìˆ˜ë³„ í‰ê· , í‘œì¤€í¸ì°¨, ìµœëŒ€, ìµœì†Œ, ì‚¬ë¶„ìœ„ìˆ˜ ë“±ì˜ ê¸°ì´ˆ í†µê³„ëŸ‰ì„ í™•ì¸í•œë‹¤. ì´ë¥¼ í†µí•´ ì–´ë–¤ ë°ì´í„°ê°€ ì´ìƒí•œì§€ íŒë‹¨í•  ìˆ˜ ìˆë‹¤. 

![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%201.png)

## info()

info() ë©”ì„œë“œë¡œ ê° ë³€ìˆ˜ë“¤ì˜ ìë£Œí˜•ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

```python
data.info()
```

![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%202.png)

ë³€ìˆ˜ì—ëŠ” ìˆ˜ì¹˜í˜• ë³€ìˆ˜ì™€ ë²”ì£¼í˜• ë³€ìˆ˜ê°€ ìˆë‹¤. object íƒ€ì…ì„ ê°€ì§„ ì»¬ëŸ¼ë“¤ì€ ëª¨ë‘ ë²”ì£¼í˜• ë³€ìˆ˜ë‹¤. ì´ë“¤ì€ êµ¬ë¶„ë˜ì–´ ì „ì²˜ë¦¬ê°€ ì§„í–‰ëœë‹¤.

ë˜í•œ, ë¼ë²¨ì— ëŒ€í•œ ìë£Œí˜• í™•ì¸ë„ í•„ìš”í•˜ë‹¤.

```python
label.info()
```

![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%203.png)

ë§Œì•½ trainsetê³¼ testsetìœ¼ë¡œ ì´ë¯¸ ë‚˜ëˆˆ ìƒíƒœë¼ë©´, ì´ë“¤ì— ëŒ€í•´ info()ë¥¼ ëª¨ë‘ ì ìš©í•´ì•¼ í•œë‹¤.

## ë²”ì£¼í˜• ë³€ìˆ˜ì™€ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ êµ¬ë¶„í•˜ê¸°

```python
cat_columns = data.select_dtypes(include='object').columns # ë²”ì£¼í˜• ë³€ìˆ˜
num_columns = data.select_dtypes(exclude='object').columns # ìˆ˜ì¹˜í˜• ë³€ìˆ˜
```

![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%204.png)

ìœ„ ì½”ë“œëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ì™€ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë¥¼ êµ¬ë¶„í•˜ì—¬ ì»¬ëŸ¼ ì´ë¦„ë§Œì„ ë½‘ì•„ë‚´ëŠ” ì½”ë“œë‹¤.

scikit-learnì„ ì“°ë©´ í•œ ì¤„ì— ì²˜ë¦¬ê°€ ê°€ëŠ¥í•˜ë©° í˜„ì—…ì—ì„œ ì£¼ë¡œ ì“´ë‹¤.

# Scaling

ë°ì´í„° ìŠ¤ì¼€ì¼ë§ì€ ë°ì´í„°ì˜ ê°’ì´ë‚˜ ë²”ìœ„ë¥¼ ë³€ê²½í•˜ì—¬ í•´ë‹¹ ê°’ë“¤ì˜ ë²”ìœ„ë¥¼ ì¡°ì •í•˜ëŠ” ì‘ì—…ì´ë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ í•™ìŠµ ê³¼ì •ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ìˆ˜ì¹˜ì  ë¶ˆì•ˆì •ì„±ì„ ì™„í™”í•˜ê±°ë‚˜ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆë‹¤.

ë”¥ëŸ¬ë‹ì˜ normalizationê³¼ ë¬¸ë§¥ìƒ ë¹„ìŠ·í•˜ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë”¥ëŸ¬ë‹ìœ¼ë¡œ CV ì‘ì—…ì„ í•  ë•Œ, RGB ì´ë¯¸ì§€ì— ëŒ€í•´ì„œ 255ì˜ ê°’ìœ¼ë¡œ ë‚˜ëˆ„ì–´ì£¼ëŠ” ê²ƒê³¼ ê°™ë‹¤. ì´ëŸ¬í•œ ì‘ì—…ì€ í…ì„œì—ì„œ ì•Œì•„ì„œ ì´ë£¨ì–´ì§„ë‹¤.

## ìŠ¤ì¼€ì¼ë§ì„ í•˜ëŠ” ì´ìœ 

ì˜¤ë²„í”¼íŒ…ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ì„œë‹¤.

ì˜ˆë¥¼ ë“¤ì–´ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ì˜ ì ˆëŒ€ê°’ì˜ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ê±°ë‚˜, í˜¹ì€ ì ˆëŒ€ê°’ì´ ë„ˆë¬´ í° ê²½ìš°(ì¦‰ ê·¹ë‹¨ì ì¸ ë¶„í¬ë¥¼ ë³´ì´ëŠ” ê²½ìš°), í•´ë‹¹ ë³€ìˆ˜ê°€ Target ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ë ¥ì´ ì œëŒ€ë¡œ **í‘œí˜„**ë˜ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤.

<aside>
ğŸ’¡ **feature representation**

ëª¨ë¸ì€ featureë¥¼ í†µí•´ íŒ¨í„´ì„ íŒŒì•…í•˜ì—¬ targetì„ ë§ì¶”ê¸° ìœ„í•œ í•™ìŠµì„ ì§„í–‰í•œë‹¤. ì´ ë•Œ, ê° featureë¥¼ í•™ìŠµí•˜ê¸° ì¢‹ê²Œ í‘œí˜„í•˜ëŠ” ê²ƒì´ë‹¤. 

</aside>

ê°’ì˜ ë²”ìœ„ê°€ ë„ˆë¬´ í¬ë©´ ëª¨ë¸ì´ ëª¨ë“  ê°’ì˜ ë²”ìœ„ë¥¼ í•™ìŠµí•˜ë¯€ë¡œ ì˜¤ë²„í”¼íŒ…ëœë‹¤. ì¦‰ ëª¨ë¸ì´ ê°€ì§„ ê°€ì¤‘ì¹˜ì˜ ê°’ì´ ê·¹ë‹¨ì ì´ê²Œ ëœë‹¤. ì˜ˆë¥¼ ë“¤ì–´, í° ê°’ì˜ ë²”ìœ„ë¥¼ í•™ìŠµí•œ ëª¨ë¸ì„ ê·¸ë˜í”„ë¡œ í‘œí˜„í•˜ë©´ ì§€ë‚˜ì¹˜ê²Œ êµ´ê³¡ì§„ ê·¸ë˜í”„ê°€ ê·¸ë ¤ì§€ê²Œ ëœë‹¤.

ë”°ë¼ì„œ, 

1. featureê°€ ëª¨ë¸ì— í•™ìŠµí•˜ê¸° ì í•©í•˜ë„ë¡ representationëœ ë°ì´í„°(ëª¨ë¸ì´ í•™ìŠµí•˜ê¸° ì¢‹ì€ ìŠ¤ì¼€ì¼ë§ ëœ ë°ì´í„°)ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜, 
2. ê·œì œë¥¼ ì ìš©í•˜ë©´ 

ê°€ì¤‘ì¹˜ë“¤ì´ ì§€ë‚˜ì¹˜ê²Œ ì»¤ì§€ëŠ” ë“±ì˜ ì˜¤ë²„í”¼íŒ…ì„ ë°©ì§€í•œë‹¤. 

ìŠ¤ì¼€ì¼ë§ì€ trainsetê³¼ tsetset ëª¨ë‘ì— ì ìš©í•œë‹¤.

## ìŠ¤ì¼€ì¼ë§ì˜ ì ìš©: Pandas DataFrame â†’ ndarray

ìŠ¤ì¼€ì¼ë§ì„ ì ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” Pandasì˜ DataFrameìœ¼ë¡œ ëœ ë°ì´í„°ë¡œë¶€í„° ndarrayë¥¼ ì¶”ì¶œí•´ì•¼ í•œë‹¤. ì•„ë˜ì™€ ê°™ì´ ì¶”ì¶œí•œë‹¤.

```python
numeric_data = data[num_columns].values # ì´ë ‡ê²Œ í•­ìƒ numpy arrayë¡œ í•˜ì§€ëŠ” ì•Šì•„ë„ ëœë‹¤.
numeric_data
```

![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%205.png)

## min-max scaling

ë‹¤ìŒì˜ ìˆ˜ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ê°’ì˜ ë²”ìœ„ë¥¼ 0~1 ì‚¬ì´ë¡œ ë³€ê²½í•œë‹¤.

$x - Min(X) \over Max(X) - Min(X)$

- $X$: ë°ì´í„° ì…‹
- $x$: ë°ì´í„° ìƒ˜í”Œ

[sklearn.preprocessing.MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html?highlight=minmax#sklearn.preprocessing.MinMaxScaler)

---

ì´ ë°ì´í„°ì— min-max scalingì„ ì ìš©í•˜ê¸° ìœ„í•œ ë°©ë²•ì€ ì•„ë˜ì™€ ê°™ë‹¤.

```python
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()

scaler.fit(numeric_data)

scaled_data = scaler.transform(numeric_data) #
scaled_data = pd.DataFrame(scaled_data, columns=num_columns)
```

ìŠ¤ì¼€ì¼ë§ ëœ ê²°ê³¼ëŠ” ndarrayì´ê¸° ë•Œë¬¸ì— ì´ë¥¼ ë‹¤ì‹œ Pandas DataFrameìœ¼ë¡œ ë§Œë“¤ì–´ì¤˜ì•¼ í•œë‹¤.

---

ìŠ¤ì¼€ì¼ë§ì´ ì ìš©ë˜ê¸° ì „ ë°ì´í„°ì™€ ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„°ë¥¼ ë¹„êµí•´ë³´ì.

```python
data[num_columns].head()
```

```python
scaled_data.head()
```

![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%206.png)

![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%207.png)

---

```python
scaled_data.describe()
```

![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%208.png)

ìŠ¤ì¼€ì¼ë§ ëœ ë°ì´í„°ëŠ” ìœ„ì™€ ê°™ì´ minê°’ì€ 0, maxê°’ì€ 1ì´ ëœë‹¤.

## standard scaling

Z-score ì •ê·œí™”

ë°ì´í„° ê°’ì„ í‘œì¤€ì •ê·œë¶„í¬ í˜•íƒœë¡œ ìŠ¤ì¼€ì¼ë§í•˜ëŠ” ë°©ë²•ì´ë‹¤. ê·¸ë ‡ë‹¤ê³  í•´ì„œ ë°ì´í„°ì˜ ë¶„í¬ë¥¼ ë°”ê¾¸ì§€ëŠ” ì•ŠëŠ”ë‹¤. ë‹¨ì§€ ë°ì´í„°ì˜ê°’ í‰ê· ì´ 0, í‘œì¤€ í¸ì°¨ê°€ 1ì´ ë˜ë„ë¡ ë‹¤ìŒì˜ ìˆ˜ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§í•œë‹¤.

$z = {{x - \mu} \over {\sigma}}$

- $\mu$: ë°ì´í„°ì˜ í‰ê· 
- $\sigma$: ë°ì´í„°ì˜ í‘œì¤€ í¸ì°¨
- $X$: ë°ì´í„° ì…‹
- $x$: ë°ì´í„° ìƒ˜í”Œ

[sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)

hospital ë°ì´í„°ì— standard scalingì„ ì ìš©í•˜ê¸° ìœ„í•œ ë°©ë²•ì€ ì•„ë˜ì™€ ê°™ë‹¤.

```python
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

scaler.fit(numeric_data)

scaled_data = scaler.transform(numeric_data)
scaled_data = pd.DataFrame(scaled_data, columns=num_columns)
```

```python
data[num_columns].head()
```

![ìŠ¤íƒ ë‹¤ë“œ ìŠ¤ì¼€ì¼ë§ ì ìš© ì „ ë°ì´í„°](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%209.png)

ìŠ¤íƒ ë‹¤ë“œ ìŠ¤ì¼€ì¼ë§ ì ìš© ì „ ë°ì´í„°

```python
scaled_data.head()
```

![ìŠ¤íƒ ë‹¤ë“œ ìŠ¤ì¼€ì¼ë§ ì ìš© í›„ ë°ì´í„°](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%2010.png)

ìŠ¤íƒ ë‹¤ë“œ ìŠ¤ì¼€ì¼ë§ ì ìš© í›„ ë°ì´í„°

```python
data[num_columns].describe()
```

![ìŠ¤íƒ ë‹¤ë“œ ìŠ¤ì¼€ì¼ë§ ì ìš© ì „ ê¸°ì´ˆí†µê³„ëŸ‰](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%2011.png)

ìŠ¤íƒ ë‹¤ë“œ ìŠ¤ì¼€ì¼ë§ ì ìš© ì „ ê¸°ì´ˆí†µê³„ëŸ‰

```python
scaled_data.describe()
```

![ìŠ¤íƒ ë‹¤ë“œ ìŠ¤ì¼€ì¼ë§ ì ìš© í›„ ê¸°ì´ˆí†µê³„ëŸ‰](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%2012.png)

ìŠ¤íƒ ë‹¤ë“œ ìŠ¤ì¼€ì¼ë§ ì ìš© í›„ ê¸°ì´ˆí†µê³„ëŸ‰

í‰ê· ê³¼ í‘œì¤€í¸ì°¨ê°€ ê°ê° 0ê³¼ 1ë¡œ ë°”ë€ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.

- 1e+2ë¼ëŠ” í‘œí˜„ì€ 1*10^(+2)ì˜ ì˜ë¯¸ë‹¤.
- ì»´í“¨í„°ëŠ” ì •í™•í•œ ì‹¤ìˆ˜ë¥¼ í‘œí˜„í•˜ì§€ ëª»í•˜ëŠ”ë° ì´ë¥¼ ë¶€ë™ì†Œìˆ˜ì  ë¬¸ì œë¼ê³  í•œë‹¤. ì´ ë¶€ë™ì†Œìˆ˜ì  ë¬¸ì œ ë•Œë¬¸ì— ìˆ˜ì¹˜ ì—°ì‚°ì— ì˜¤ì°¨ê°€ ë°œìƒí•˜ê¸°ë„ í•œë‹¤. ì´ëŸ¬í•œ ì´ìœ ë¡œ, ë¸”ë¡ì²´ì¸ì—ì„œëŠ” 0.001ê°œ ì½”ì¸ì„ ì—„ì²­ë‚˜ê²Œ í° ì •ìˆ˜ë¡œ í‘œí˜„í•œë‹¤. ì‹¤ì œ ìœ ì €ì—ê²ŒëŠ” í•´ë‹¹ decimalê°’ìœ¼ë¡œ ë‚˜ëˆ„ì–´ì£¼ì–´ ì›ë˜ì˜ ì†Œìˆ˜ì  í‘œí˜„ìœ¼ë¡œ ë³´ì—¬ì¤€ë‹¤.
    - ì‹œìŠ¤í…œì—ì„œ ì‹¤ìˆ˜í˜•ì„ ë¯¼ê°í•˜ê²Œ ì“¸ ìˆ˜ë°–ì— ì—†ëŠ” ì¼€ì´ìŠ¤ì—ì„œëŠ” ë¶€ë™ì†Œìˆ˜ì ì¸ float íƒ€ì…ì„ ì•ˆì“°ê³  ê³ ì •ì†Œìˆ˜ì ì¸ decimal íƒ€ì…ì„ ì“´ë‹¤. ì´ ë‘˜ì€ ì‹¤ìˆ˜ë¥¼ í‘œí˜„í•˜ëŠ” ë°©ì‹ì´ ë‹¤ë¥´ë‹¤. ë¶€ë™ì†Œìˆ˜ì ì€ ì†Œìˆ˜ì ì˜ ìœ„ì¹˜ê°€ ê³ ì •ë˜ì§€ ì•ŠëŠ” ë°˜ë©´, ê³ ì •ì†Œìˆ˜ì ì€ ì†Œìˆ˜ì ê³¼ ìë¦¿ìˆ˜ë¥¼ ê°•ì œí•œë‹¤. ë•Œë¬¸ì— decimal íƒ€ì…ì— ëŒ€í•´ì„œëŠ” ë³µì¡í•œ ì—°ì‚°ì´ ì´ë£¨ì–´ì§„ë‹¤.
    - TensorëŠ” floatì— ê°€ê¹ë‹¤. ë³´í†µì€ ì†Œìˆ˜ì ì— ì˜ˆë¯¼í•  ë•Œì— decimalì„ ì“°ëŠ”ë°, ì†Œìˆ˜ì ì´ ëª¨ë¸ì˜ í•™ìŠµì— ë¼ì¹˜ëŠ” ì˜í–¥ì´ ê·¸ë¦¬ í¬ì§€ ì•Šê¸° ë•Œë¬¸ì— float íƒ€ì…ì„ ì¨ë„ ë¬´ë°©í•˜ë‹¤. ì˜¤íˆë ¤ decimalë¡œ ë§Œë“¤ì–´ì£¼ëŠ” ì—°ì‚°ì´ ë” í´ ê²ƒì´ë‹¤.

## ì–´ë–¤ ë°©ë²•ì„ ì¨ì•¼ í•˜ë‚˜?

ì–´ëŠ ìƒí™©ì—ì„œë‚˜ ê°€ì¥ ì¢‹ì€ ë°©ë²•ì€ ì—†ë‹¤. ë°ì´í„°ì— ë”°ë¼ì„œ ë‹¤ë¥¼ ìˆ˜ ìˆê³ , ë„ë©”ì¸ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ë„ ìˆë‹¤. 

# Transformation

ë°ì´í„° ìŠ¤ì¼€ì¼ë§ì€ ë°ì´í„°ì˜ ê°’ì´ë‚˜ ë²”ìœ„ë¥¼ ë³€ê²½í•˜ì—¬ í•´ë‹¹ ê°’ë“¤ì˜ ë²”ìœ„ë¥¼ ì¡°ì •í•´ì£¼ì§€ë§Œ,  ë°ì´í„° ë¶„í¬ì˜ ëª¨ì–‘ì„ ë³€ê²½í•˜ì§€ëŠ” ì•ŠëŠ”ë‹¤. ë°ì´í„° ì¹˜ìš°ì¹œ ë¶„í¬(skew)ì˜ í˜•íƒœë¥¼ ë³´ì •í•´ì£¼ë ¤ë©´ ë°ì´í„° ë³€í™˜(transformation)ì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤. ì´ëŸ¬í•œ ë³€í™˜ì€ ë°ì´í„°ê°€ ì •ê·œ ë¶„í¬ë¥¼ ë”°ë¥´ë„ë¡ ë§Œë“¤ê±°ë‚˜ ë‹¤ë¥¸ í˜•íƒœì˜ ë¶„í¬ë¥¼ ê°€ì§€ë„ë¡ ì¡°ì •í•˜ëŠ” ê²ƒì´ë‹¤.

ì¦‰, ë°ì´í„° ìŠ¤ì¼€ì¼ë§ê³¼ ë°ì´í„° ë³€í™˜ì€ ì„œë¡œ ë‹¤ë¥¸ ëª©ì ìœ¼ë¡œ ì‚¬ìš©ëœë‹¤.

```python
scaled_data['revenue2'].hist(bins=20) 
```

![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%2013.png)

í˜„ì¬ ë°ì´í„° ë¶„í¬ëŠ” ë¡±í…Œì¼ì„ ê°€ì§„ë‹¤. 

## Log transformation

ë¡œê·¸ë¥¼ ì·¨í–ˆì„ ë•Œ ë…¸ë§ë¶„í¬ê°€ ë˜ê²Œ í•œë‹¤. ë³€ìˆ˜ì˜ ë²”ìœ„ê°€ **ì–‘ìˆ˜ì¸ ê²½ìš°ì—ë§Œ** ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ê° ë³€ìˆ˜ì— ëŒ€í•´ ìì—° ë¡œê·¸ë¥¼ ì·¨í•œë‹¤.

```
scaled_data['log_revenue2'] = np.log1p(data['revenue2'])
scaled_data['log_revenue2'].hist(bins=50)
```

![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%2014.png)

ì•ì„œ ë³¸ ë°ì´í„° ë¶„í¬ì— Log transformationë¥¼ ì ìš©í•˜ë©´ ìœ„ì™€ ê°™ì´ ë‚˜ì˜¨ë‹¤. ë¬´ì—‡ì´ ì˜ëª»ëœê±¸ê¹Œ? 0ê°’ì´ ì§€ë‚˜ì¹˜ê²Œ ë§ì€ ìƒí™©ì´ë¼, 0ì„ ì œì™¸í•˜ê³  ë³´ì•„ì•¼ í•œë‹¤.

```python
scaled_data['log_revenue2'].loc[scaled_data['log_revenue2'] > 0].hist(bins=50) # ê·¸ë‚˜ë§ˆ ëª¨ì—¬ìˆëŠ”ê²Œ ì¢‹ë‹¤.
```

![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%2015.png)

ìœ„ì™€ ê°™ì´ ì •ê·œë¶„í¬ì˜ ëª¨ì–‘ì— ê°€ê¹Œì›Œì¡Œë‹¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

í•˜ì§€ë§Œ ìš°ë¦¬ëŠ” 0ì„ ì œì™¸í–ˆëŠ”ë°, 0 ë˜ëŠ” ìŒìˆ˜ê°€ ìˆëŠ” ê²½ìš°ì—” ë¡œê·¸ë¥¼ ì·¨í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— ì‹¤ì€ ë‹¤ë¥¸ ë°©ë²•ì„ ì¨ì•¼ í•œë‹¤.

## Box-cox transformation

Log ë³€í™˜ê³¼ ë™ì¼í•˜ê²Œ, ì–‘ìˆ˜ê°’ì—ë§Œ ì ìš©í•  ìˆ˜ ìˆë‹¤.

Box-Cox ìˆ˜ì‹ì—ì„œ, Lambda ê°’ì´ 0ì¼ ë• Log ë³€í™˜ê³¼ ë™ì¼í•˜ë‹¤.

```python
from sklearn.preprocessing import PowerTransformer 

trans = PowerTransformer(method='box-cox')

scaled_data['box_cox_revenue2'] = trans.fit_transform(scaled_data['revenue2'].values.reshape(-1, 1) + 1)
scaled_data['box_cox_revenue2'].hist(bins=40)
```

![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%2016.png)

## Yeo-Johnson transformation

Log ë³€í™˜ê³¼ Box-Cox ë³€í™˜ì˜ í•œê³„ë¥¼ ê°œì„ í•œ ë°©ë²•ìœ¼ë¡œì„œ, ìŒìˆ˜ë¥¼ ê°€ì§„ ë³€ìˆ˜ê°’ë„ ê°€ëŠ¥í•˜ë‹¤. 

```python
from sklearn.preprocessing import PowerTransformer

trans = PowerTransformer(method='yeo-johnson')

scaled_data['yeo_johnson_revenue2'] = trans.fit_transform(scaled_data['revenue2'].values.reshape(-1, 1))
scaled_data['yeo_johnson_revenue2'].hist(bins=40)
```

![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%2017.png)

## Quantile transformation

ê°€ì¥ ìì£¼ ë°œìƒí•˜ëŠ” ê°’(the most frequent values) ì£¼ìœ„ë¡œ ë¶„í¬ë¥¼ ì¡°ì •í•œë‹¤. ì´ìƒì¹˜ì˜ ì˜í–¥ì„ ê°ì†Œì‹œì¼œ ì¤€ë‹¤.

[sklearn.preprocessing.QuantileTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html#sklearn.preprocessing.QuantileTransformer)

```python
from sklearn.preprocessing import QuantileTransformer

trans = QuantileTransformer(output_distribution='normal')

scaled_data['quantile_revenue2'] = trans.fit_transform(scaled_data['revenue2'].values.reshape(-1, 1))
scaled_data['quantile_revenue2'].hist(bins=40)
```

![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%2018.png)

## trainset, testset ëª¨ë‘ì— ì ìš©í•˜ëŠ”ê°€? YES

trainset ë¿ë§Œ ì•„ë‹ˆë¼, testsetì—ë„ ë§ˆì°¬ê°€ì§€ë¡œ ê° featureì— ëŒ€í•´ ë™ì¼í•˜ê²Œ scalingâ†’transformation ê³¼ì •ì„ ì™„ë²½íˆ ë˜‘ê°™ì´ ì ìš©í•´ì•¼ í•œë‹¤. ì´ë¥¼ ìœ„í•´ ë”°ë¡œ í•¨ìˆ˜ë¡œ trainsetê³¼ testsetì´ ì²˜ë¦¬ë˜ë„ë¡ ë§Œë“¤ê¸°ë„ í•œë‹¤.

## ì–´ë–¤ ë°©ë²•ì„ ì¨ì•¼ í•˜ë‚˜?

ì–´ë–¤ ë°©ë²•ì´ ì œì¼ ì¢‹ë‹¤ëŠ” ê±´ ì—†ë‹¤. ëª¨ì–‘ì´ ì´ì˜ê²Œ ì˜ ë‚˜ì˜¤ê²Œ ë§Œë“œëŠ” ë°©ë²•ì„ ì„ íƒí•´ì•¼ í•˜ë©°, ì´ëŠ” featureë§ˆë‹¤ ë‹¤ë¥¸ ë°©ë²•ì„ ì ìš©í•´ì•¼í•¨ì„ ì˜ë¯¸í•œë‹¤. 

â€˜ëª¨ì–‘ì´ ì´ì˜ê²Œ ì˜ ë‚˜ì˜¨ë‹¤ëŠ” ê²ƒâ€™ì€ skewness(`pandas.DataFrame.skew`) ê°’ìœ¼ë¡œ ì •ëŸ‰ì ìœ¼ë¡œ íŒë‹¨ ê°€ëŠ¥í•˜ë©°, ì¼ë°˜ì ìœ¼ë¡œëŠ” ì´ ê°’ì´ ì‘ì€ ê²ƒì´ ì¢‹ë‹¤. í•˜ì§€ë§Œ skewness ê°’ì„ ì°¸ê³ í•´ì„œ ì „ì²˜ë¦¬ë¥¼ í–ˆìŒì—ë„ ëª¨ë¸ë§ ê²°ê³¼ê°€ ì¢‹ì§€ ì•Šì„ ìˆ˜ë„ ìˆë‹¤ëŠ” ì ì€ ì°¸ê³ í•´ì•¼ í•œë‹¤.

![[https://scikit-learn.org/stable/auto_examples/preprocessing/plot_map_data_to_normal.html#sphx-glr-auto-examples-preprocessing-plot-map-data-to-normal-py](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_map_data_to_normal.html#sphx-glr-auto-examples-preprocessing-plot-map-data-to-normal-py)

ê° ë³€í™˜ë§ˆë‹¤ ê²°ê³¼ê°€ ì¡°ê¸ˆì”© ë‹¤ë¥¸ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%2019.png)

[https://scikit-learn.org/stable/auto_examples/preprocessing/plot_map_data_to_normal.html#sphx-glr-auto-examples-preprocessing-plot-map-data-to-normal-py](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_map_data_to_normal.html#sphx-glr-auto-examples-preprocessing-plot-map-data-to-normal-py)

ê° ë³€í™˜ë§ˆë‹¤ ê²°ê³¼ê°€ ì¡°ê¸ˆì”© ë‹¤ë¥¸ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.

[sklearn.preprocessing.PowerTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer)

## ìŠ¤ì¼€ì¼ë§ í›„ ë³€í™˜ì¸ê°€, ë³€í™˜ í›„ ìŠ¤ì¼€ì¼ë§ì¸ê°€?

ë‘ ê°€ì§€ ë°©ë²• ëª¨ë‘ ì‚¬ìš© ê°€ëŠ¥í•˜ì§€ë§Œ, ì¼ë°˜ì ìœ¼ë¡œëŠ” ìŠ¤ì¼€ì¼ë§ í›„ì— ë³€í™˜í•˜ëŠ” ë°©ë²•ì´ ë” í”í•˜ê²Œ ì‚¬ìš©ëœë‹¤. ìŠ¤ì¼€ì¼ë§ì´ ë°ì´í„°ì˜ ë‹¨ìœ„ë‚˜ í¬ê¸°ë¥¼ ì¡°ì •í•˜ëŠ”ë° ë„ì›€ì„ ì£¼ê³ , ê·¸ í›„ì— ë¶„í¬ ë³€í™˜ì„ í†µí•´ ë°ì´í„°ë¥¼ ëª¨ë¸ë§í•˜ê¸° ì¢‹ì€ í˜•íƒœë¡œ ë§Œë“¤ê¸° ë•Œë¬¸ì´ë‹¤. 

# Imputation

ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë°©ë²•ì„ imputationì´ë¼ í•œë‹¤.

ì •í˜• ë°ì´í„°ë¥¼ ë‹¤ë£¨ë‹¤ë³´ë©´, í˜„ì¬ ì´ ë…¸íŠ¸ì—ì„œ ì–¸ê¸‰í•œ ë°ì´í„°ì²˜ëŸ¼, ê°’ì´ NaN(Not a Number or Null)ìœ¼ë¡œ ë˜ì–´ìˆëŠ” ê²½ìš°ê°€ ìˆë‹¤([NaNê°’ ì—¬ë¶€ í™•ì¸](https://www.notion.so/NaN-0a6e66fe36a34ec3ac2dc8c3e6c8533f?pvs=21)). ì´ëŸ¬í•œ ê°’ì„ ê²°ì¸¡ì¹˜ë¼ í•œë‹¤.

ì£¼ì˜í•  ì ì€, ê²°ì¸¡ì¹˜ ìì²´ì— ì˜ë¯¸ê°€ ìˆì„ ìˆ˜ë„ ìˆë‹¤ëŠ” ì ì´ë‹¤. ì¦‰, ì„¤ë¬¸ì¡°ì‚¬ ë“±ì—ì„œ í•„ìˆ˜ê°’ì´ ì•„ë‹Œ ê°’ë“¤ì€ ì‹¬ë¦¬ì ì¸ ì´ìœ ë¡œ ê³µë°±ìœ¼ë¡œ ë‚¨ê¸´ ê²½ìš° ë“±ì´ ê·¸ëŸ¬í•œ ê²½ìš°ë‹¤. ì´ëŸ´ ê²½ìš°, í•´ë‹¹ ê²°ì¸¡ì¹˜ë“¤ì„ ë³„ë„ì˜ ìƒˆë¡œìš´ featureë¡œ ë§Œë“¤ì–´ì„œ ì´ëŸ¬í•œ NaNê°’ì„ ê°€ì§„ ìƒ˜í”Œ(row)ë“¤ì€ ë³„ë„ì˜ ì˜ë¯¸ë¥¼ ê°–ëŠ” ì‚¬ëŒë“¤ì´ë¼ëŠ” ì‹ìœ¼ë¡œë„ feature engineeringì„ ì§„í–‰í•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ë„ë©”ì¸ì— ëŒ€í•œ ì´ìœ ê°€ í•„ìˆ˜ì ì´ë‹¤. ë”°ë¼ì„œ í•´ë‹¹ ê²°ì¸¡ì¹˜ë“¤ì„ ì±„ì›Œì„œ ì¨ë„ ë ì§€, ê·¸ëŒ€ë¡œ ì‚¬ìš©í• ì§€ ë“±ì€ ë„ë©”ì¸ ì „ë¬¸ê°€ë“¤ê³¼ í˜‘ì˜ê°€ í•„ìˆ˜ì ì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤.

í•˜ì§€ë§Œ ì™ ë§Œí•œ ì¼€ì´ìŠ¤ì—ì„œëŠ” ê²°ì¸¡ì¹˜ëŠ” ì˜ë¯¸ê°€ ì—†ë‹¤. 

## ê²°ì¸¡ì¹˜ í™•ì¸: `isna()` & `sum()`

ê²°ì¸¡ì¹˜ë¥¼ í™•ì¸í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ Pandasì˜Â `isna()` ì™€ `sum()`Â ë©”ì†Œë“œì˜ ì¡°í•©ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

`isna()`ëŠ” ê°’ì´ nullì¸ì§€ ì²´í¬í•œ í›„, T/Fë¥¼ ë°˜í™”í•œë‹¤.

```python
pd.isna(data)
```

![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%2020.png)

ì´ì— ëŒ€í•´ `sum()` ë©”ì„œë“œë¥¼ ì ìš©í•´ë‚˜ê°€ë©´ nullê°’ ì²´í¬ê°€ ì‰¬ì›Œì§„ë‹¤. Pandasì˜`sum()`ë©”ì„œë“œëŠ” ìì²´ì ìœ¼ë¡œ ê°’ì„ ìˆ«ìë¡œ ë°”ê¿€ ìˆ˜ ìˆëŠ”ì§€ íŒë‹¨í•œ í›„, ê°’ì„ ë°”ê¾¸ì–´ ì—°ì‚°ì„ ì§„í–‰í•˜ê¸° ë•Œë¬¸ì´ë‹¤.

```python
pd.isna(data).sum()
```

![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%2021.png)

```python
pd.isna(data).sum().sum() # 425
```

missingnoë¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë“±ì„ ì“°ë©´ ì‹œê°í™”ë„ ê°€ëŠ¥í•˜ë‹¤.

```python
from missingno import matrix
matrix(data)
```

![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%2022.png)

## ìˆ˜ì¹˜í˜• ë³€ìˆ˜ì˜ ê²°ì¸¡ì¹˜ì— ëŒ€í•œ ì²˜ë¦¬

### Mean

ìˆ˜ì¹˜í˜• ë³€ìˆ˜ì˜ ê²°ì¸¡ì¹˜ì— ì ìš©í•˜ëŠ” ë°©ë²•ìœ¼ë¡œì„œ, í‰ê·  ê°’ìœ¼ë¡œ ê²°ì¸¡ì¹˜ë¥¼ ì±„ìš°ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.

í‰ê· ì€ ëª¨ë“  ê°’ì„ ê³ ë ¤í•˜ê¸° ë•Œë¬¸ì—, ì§€ë‚˜ì¹˜ê²Œ ì‘ê±°ë‚˜ í° ê°’(ì¦‰, ì´ìƒì¹˜ê°’)ë“¤ì˜ ì˜í–¥ì„ ë§ì´Â ë°›ëŠ”ë‹¤. ì¦‰, í‰ê· ì˜ í•¨ì •ì— ë¹ ì§ˆ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ, ì´ìƒì¹˜ê°€ ì—†ë‹¤ëŠ” ì „ì œí•˜ì— ì¨ì•¼ í•˜ë©°, ì´ìƒì¹˜ê°€ ìˆë‹¤ë©´ ì´ìƒì¹˜ë¥¼ ì œê±°í•˜ì—¬ ì ìš©í•´ì•¼ í•œë‹¤. 

í‰ê· ì€ ì•„ë˜ ìˆ˜ì‹ê³¼ ê°™ì´ ëª¨ë“  ìƒ˜í”Œì˜ ê°’ì„ ë”í•˜ê³ , ìƒ˜í”Œì˜ ê°œìˆ˜ë¡œ ë‚˜ëˆ„ì–´ ê³„ì‚°í•œë‹¤.

$E(x) = {\sum x \over n}$

ì‘ì—…ì„ ìœ„í•´ ë°ì´í„°ë¥¼ ë³µì‚¬í•´ë‘”ë‹¤.

```python
mean_df = data.copy()
```

---

ë‹¤ìŒê³¼ ê°™ì´ ì ìš©í•œë‹¤.

```python
from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy='mean') 
imputer.fit(mean_df[num_columns])
mean_df[num_columns] = imputer.transform(mean_df[num_columns])

pd.isna(mean_df[num_columns]).sum().sum() # 0
```

ê²°ì¸¡ì¹˜ê°€ ëª¨ë‘ ì±„ì›Œì¡ŒìŒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

### Median

ìˆ˜ì¹˜í˜• ë³€ìˆ˜ì˜ ê²°ì¸¡ì¹˜ì— ì ìš©í•˜ëŠ” ë°©ë²•ìœ¼ë¡œì„œ, ë°ì´í„°ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì¤„ ì„¸ì› ì„ ë•Œ ë”± ì¤‘ê°„ì— ìˆëŠ” ê°’ìœ¼ë¡œ ì±„ìš°ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. ë§Œì•½ ì¤‘ê°„ê°’ì´ í•˜ë‚˜ê°€ ì•„ë‹ˆë¼ë©´ ì „í›„ì˜ ë‘ ê°’ì˜ í‰ê· ì„ ì¤‘ê°„ê°’ìœ¼ë¡œ ì •í•œë‹¤. 

Medianì€ ì´ìƒì¹˜ì— ì˜í–¥ì„ ëœ ë°›ëŠ” ë°©ë²•ì´ë‹¤. ë”°ë¼ì„œ í‰ê· ì˜ í•¨ì •ì— ë¹ ì§€ì§€ ì•ŠëŠ”ë‹¤.

Medianì€ ê°’ë“¤ì„ ì •ë ¬í•œ í›„, ì¤‘ì•™ì— ìœ„ì¹˜í•œ ê°’ìœ¼ë¡œ êµ¬í•œë‹¤.

```python
median_df = data.copy()

imputer = SimpleImputer(strategy='median')
imputer.fit(median_df[num_columns])
median_df[num_columns] = imputer.transform(median_df[num_columns])

pd.isna(median_df[num_columns]).sum().sum() # 0
```

### Iterative Impute

MICE(Multiple Imputation by Chained Equations)

ìˆ˜ì¹˜í˜• ë³€ìˆ˜ì˜ ê²°ì¸¡ì¹˜ì— ì ìš©í•˜ëŠ” ë°©ë²•ìœ¼ë¡œì„œ, ë‹¤ë¥¸ rowê°’ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ê²°ì¸¡ì¹˜ì˜ ê°’ì„ iterativeí•˜ê²Œ ê°œì„ ì‹œì¼œ ë‚˜ê°€ëŠ” ë°©ì‹(Round robin ë°©ì‹)ì´ë‹¤. ì´ë¥¼ ìœ„í•´ ê° ë³€ìˆ˜ì— íšŒê·€ ëª¨ë¸ì„ ì ìš©í•˜ì—¬ ê²°ì¸¡ì¹˜ë¥¼ ì˜ˆì¸¡í•˜ê³ , ì´ëŸ¬í•œ ë°˜ë³µì„ ì—¬ëŸ¬ ë²ˆ ìˆ˜í–‰í•˜ì—¬ ê²°ì¸¡ì¹˜ë¥¼ ì¶”ì‚°í•œë‹¤. 

MICEëŠ” ë‚´ë¶€ì ìœ¼ë¡œ íšŒê·€ì‹ì´ ì ìš©ëœë‹¤(ë‹¤ë¥¸ ë³€ìˆ˜ë“¤ì„ ë…ë¦½ ë³€ìˆ˜ë¡œ ì‚¬ìš©í•˜ì—¬ íšŒê·€ì‹ì„ ì í•©í•˜ê³ , ê²°ì¸¡ì¹˜ ê°’ì„ ì±„ì›Œì•¼ í•˜ëŠ” ì»¬ëŸ¼ì„ ì¢…ì† ë³€ìˆ˜ë¡œ í•œë‹¤).

1. ê° ê²°ì¸¡ì¹˜ë¥¼ ì¼ë‹¨ì€ í•´ë‹¹ ë³€ìˆ˜ì˜ í‰ê· ìœ¼ë¡œ ì´ˆê¸°í™”í•œë‹¤.
2. ëŒ€ì²´í•  ë³€ìˆ˜ì˜ ê²°ì¸¡ì¹˜ë¥¼ ì œì™¸í•œ ìƒíƒœë¡œ, ë‹¤ë¥¸ ë³€ìˆ˜ë“¤ì„ ëª¨ë‘ í¬í•¨í•œ íšŒê·€ëª¨ë¸ì„ ë§Œë“¤ê³ , ê²°ì¸¡ì¹˜ê°’ì„ ì¶”ì‚°í•œë‹¤.
3. ë‹¤ë¥¸ ê²°ì¸¡ì¹˜ ë³€ìˆ˜ì— ëŒ€í•´ì„œ ë™ì¼í•˜ê²Œ ë°˜ë³µí•œë‹¤.
4. í•´ë‹¹ ì´í„°ë ˆì´ì…˜ì—ì„œ ë§¨ ì²˜ìŒì— í• ë‹¹í–ˆë˜ ê°’ê³¼ì˜ ì°¨ì´ë¥¼ ê³„ì‚°í•œë‹¤.
5. í•´ë‹¹ ê°’ì˜ ì°¨ì´ê°€ 0ì´ ë  ë•Œ(ìˆ˜ë ´)ê¹Œì§€ ë°˜ë³µí•œë‹¤.

MICE ë°©ë²•ì€ ì¼ë°˜ì ìœ¼ë¡œ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ì— ì ìš©ëœë‹¤. 

MICEì˜ ì ìš©ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

[sklearn.impute.IterativeImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html?highlight=mice)

```python
impute_df = data.copy()

from sklearn.experimental import enable_iterative_imputer # ì•„ì§ ê³µì‹ ê¸°ëŠ¥ì´ ì•„ë‹ˆë¼ì„œ ì´ ë¼ì¸ì„ ë„£ì–´ì•¼ í•œë‹¤.
from sklearn.impute import IterativeImputer

# ?IterativeImputer

imp_mean = IterativeImputer(random_state=0) 
impute_df[num_columns] = imp_mean.fit_transform(impute_df[num_columns])

pd.isna(impute_df[num_columns]).sum().sum()
```

`from sklearn.experimental import enable_iterative_imputer`:ì´ ë¶€ë¶„ì´ í•„ìš”í•œ ì´ìœ ëŠ”, í•´ë‹¹ ê¸°ëŠ¥ì´ ì•„ì§ ê³µì‹ ê¸°ëŠ¥ì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì´ë‹¤.

IterativeImputerì—ì„œ ì£¼ë¡œ ê±´ë“¤ íŒŒë¼ë¯¸í„°ëŠ” `max_iter`ì™€ `tol`ì´ë‹¤. ì´ ë‘ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•¨ìœ¼ë¡œì¨ imputationì— ê±¸ë¦¬ëŠ” ì‹œê°„ì´ ì§€ë‚˜ì¹˜ê²Œ ì˜¤ë˜ ê±¸ë¦¬ì§€ ì•Šë„ë¡ ì¡°ì •í•  ìˆ˜ ìˆë‹¤.

## ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ê²°ì¸¡ì¹˜ì— ëŒ€í•œ ì²˜ë¦¬

### Mode

ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ê²°ì¸¡ì¹˜ì— ì ìš©í•˜ëŠ” ë°©ë²•ìœ¼ë¡œì„œ, ìµœë¹ˆê°’ìœ¼ë¡œ ê²°ì¸¡ì¹˜ë¥¼ ì±„ìš°ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.

```python
mode_df = data.copy()

imputer = SimpleImputer(strategy='most_frequent')
imputer.fit(mode_df[cat_columns])
mode_df[cat_columns] = imputer.transform(mode_df[cat_columns])

pd.isna(mode_df[cat_columns]).sum().sum()
```

# Encoding

ì¸ì½”ë”©ì´ë€ ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë¡œ ë‚˜íƒ€ë‚´ëŠ” ê²ƒì„ ë§í•œë‹¤. ë²”ì£¼í˜• ë°ì´í„°ëŠ” ì¢…ì¢… ë¬¸ìí˜•íƒœì´ê¸°ë„ í•œë°, ì»´í“¨í„°ê°€ ìˆ«ìë¡œë§Œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤.

## Label Encoding

ë¼ë²¨ ì¸ì½”ë”©ì€ nê°œì˜ ë²”ì£¼í˜• ë°ì´í„°ë¥¼ `0`~`n-1` ì‚¬ì´ì˜ ìˆ˜ë¡œ í‘œí˜„í•˜ëŠ” ê°„ë‹¨í•œ ë°©ë²•ì´ë‹¤.

```
BMW : 0
VOLVO : 1
KIA : 2
```

ë¼ë²¨ ì¸ì½”ë”©ì€ ê°„ë‹¨í•œ ë°©ë²•ì´ì§€ë§Œ, 'ì†Œí˜•'ê³¼ 'ì¤‘í˜•'ì´ë¼ëŠ” ì˜ë¯¸ì˜ ì°¨ì´ë¥¼ ë°˜ì˜í•˜ì§€ëŠ” ì•ŠëŠ”ë‹¤. ë§Œì•½ ìˆœì„œê°€ ì¤‘ìš”í•œ ë²”ì£¼í˜• ë°ì´í„°ë¼ë©´, Ordinal Encodingì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤.

[https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html?highlight=label encoder#sklearn.preprocessing.LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html?highlight=label%20encoder#sklearn.preprocessing.LabelEncoder)

```python
data = pd.read_csv(example_file)
label = pd.DataFrame(data['OC'])

label.head() # ëª¨ë¸ì€ ìˆ«ìë¥¼ ìš”êµ¬í•œë‹¤.
```

![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%2023.png)

```python
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

le.fit(label)

# 
le.classes_ # array([' close', 'open'], dtype=object)
```

ë§¨ ëì— ì–¸ë”ë¼ì¸(`_`)ì´ ìƒê¸°ëŠ” ê²ƒì€ fitì´ ìˆ˜í–‰ëœ í›„ì— ìƒì„±ëœë‹¤.

Encodingì˜ ë²ˆí˜¸ ë¶€ì—¬ëŠ”, fitì´ ëë‚œ LabelEncoder ê°ì²´ì˜ classes_ ì†ì„±ì— ìˆëŠ” ì¸ë±ìŠ¤ ìˆœì„œëŒ€ë¡œ ë¶€ì—¬ëœë‹¤. ë”°ë¼ì„œ, ìœ„ ê²°ê³¼ì— ì˜í•˜ë©´ closeë¶€í„° 0ìœ¼ë¡œ ì¸ì½”ë”© ì²˜ë¦¬ëœë‹¤. 

ì´ì œ, ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ì‹¤ì œ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë¡œ ë³€í™˜í•˜ì.

```python
label_encoded = le.transform(label)
```

---

```python
le_df = pd.DataFrame(label_encoded, columns = ['label_encoded'])

result = pd.concat([label, le_df], axis=1)
result.sort_values('label_encoded', inplace=True) # íŠ¹ì • ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•  ë•Œ sort_values

result.head(20) # closeê°€ ê°œìˆ˜ê°€ ì ì€ imbalanced ë°ì´í„°ë‹¤.
```

![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%2024.png)

## One-Hot Encoding

ì›í•« ì¸ì½”ë”©ì€ nê°œì˜ ë²”ì£¼í˜• ë°ì´í„°ë¥¼ nê°œì˜ ë¹„íŠ¸(0,1) ë²¡í„°ë¡œ í‘œí˜„í•œë‹¤. 

```
BMW : [1, 0, 0]
VOLVO : [0, 1, 0]
KIA : [0, 0, 1]
```

ì›í•« ì¸ì½”ë”©ìœ¼ë¡œ ë²”ì£¼í˜• ë°ì´í„°ë¥¼ ë‚˜íƒ€ë‚´ë©´, ê° ë²¡í„°ë¼ë¦¬ëŠ” ê·¸ ë‚´ì  ê°’ì´ 0ì´ ë‚˜ì˜¨ë‹¤. ì´ ë§ì€ ê³§, ì„œë¡œ ë‹¤ë¥¸ ë²”ì£¼ ë°ì´í„° ë¼ë¦¬ëŠ” ë…ë¦½ì ì¸ ê´€ê³„ë¥¼ í˜•ì„±í•˜ê³  ìˆë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.

ë‹¨, ì›í•« ì¸ì½”ë”© ë°©ì‹ì€ ë‘ ê°€ì§€ ë¬¸ì œê°€ ìˆë‹¤.

1. **ì°¨ì›ì˜ ì €ì£¼**
    
    ì°¨ì›ì´ ëŠ˜ì–´ë‚ ìˆ˜ë¡(featureì˜ ê°œìˆ˜ê°€ ë§ì•„ì§ˆìˆ˜ë¡) ëª¨ë¸ì˜ ì„±ëŠ¥ì€ ë‚®ì•„ì§„ë‹¤.
    
2. **ë©”ëª¨ë¦¬ ë‚­ë¹„ â‡’** `OneHotEncoder`ì˜ `sparse` íŒŒë¼ë¯¸í„°ë¥¼ `False`ë¡œ í•œë‹¤.
    
    0ê°’ì´ ëŒ€ë¶€ë¶„ì¸ sparse matrixë¥¼ í˜•ì„±í•˜ê³  ì´ ì •ë³´ë¥¼ ë©”ëª¨ë¦¬ì— ìœ ì§€ì‹œì¼œì•¼ í•œë‹¤.
    

[sklearn.preprocessing.OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder)

ì°¸ê³ ë¡œ, scikit-learnì˜ One-hot EncoderëŠ” ndarray í–‰ë ¬ì— ëŒ€í•´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ê¸° ë–„ë¬¸ì—, Pandas DataFrameì„ ndarrayë¥¼ ì¶”ì¶œí•´ì„œ ì‚¬ìš©í•´ì•¼ í•œë‹¤.

```python
from sklearn.preprocessing import OneHotEncoder
ohe = OneHotEncoder(sparse=False) 
ohe.fit(label)

one_hot_encoded = ohe.transform(label)
one_hot_encoded
# array([[0., 1.],
#        [0., 1.],
#        [0., 1.],
#        [0., 1.],
#        [1., 0.],
#        [0., 1.],
# 	     ....
```

`OneHotEncoder`ì˜ `sparse` íŒŒë¼ë¯¸í„°ë¥¼ `False`ë¡œ í•˜ë©´, ê°’ì´ ìˆì–´ì•¼ í•  ìœ„ì¹˜ì™€ í•´ë‹¹ ê°’ë§Œ í‘œí˜„í•˜ê¸° ë•Œë¬¸ì—, ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ë†’ì¼ ìˆ˜ ìˆë‹¤. 

defaultê°’ì€ Trueì´ë‹¤.(ì•„ë˜ ì½”ë“œ ì°¸ê³ )

```python
from sklearn.preprocessing import OneHotEncoder
ohe_sparse = OneHotEncoder()
ohe_sparse.fit(label)

ohe_hot_sparse = ohe_sparse.transform(label)
ohe_hot_sparse
# <301x2 sparse matrix of type '<class 'numpy.float64'>'
#	with 301 stored elements in Compressed Sparse Row format>
```

OneHotEncoderì˜ ê²°ê³¼ë¡œ ë‚˜ì˜¨ ê°ì²´ì˜ ë‚´ìš©ì„ ë³´ë ¤ë©´ arrayë¡œ ë°”ê¿”ì•¼ í•œë‹¤.

```python
ohe_hot_sparse.toarray()

# array([[0., 1.],
#        [0., 1.],
#        [0., 1.],
#        [0., 1.],
#        [1., 0.],
#        [0., 1.],
# 	     ....
```

---

scikit-learnì— ì˜í•´ One-Hot Encodingëœ ë¼ë²¨ ë°ì´í„°ë¥¼ ë‹¤ì‹œ Pandas DataFrameìœ¼ë¡œ ë°”ê¿”ì¤€ë‹¤.

```python
ohe_df = pd.DataFrame(one_hot_encoded, columns = ohe.categories_[0])
result = pd.concat([label, ohe_df], axis=1)

result.head(10)
```

![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20eb7a0990c3344d32922f9a09055b3501/Untitled%2025.png)

## Ordinal Encoding

ì¹´í…Œê³ ë¦¬ ê°„ì˜ ìˆœì„œê°€ ì˜ëª» ë¶€ì—¬ë˜ë©´ ëª¨ë¸ì´ ì˜ëª»ëœ ê´€ê³„ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ì˜¬ë°”ë¥¸ ìˆœì„œë¥¼ ê²°ì •í•´ì•¼ í•œë‹¤. 

ë˜í•œ, ì˜¤ë””ë„ ì¸ì½”ë”©ì€ ì¹´í…Œê³ ë¦¬ ê°„ì˜ ê±°ë¦¬ê°€ ì¼ì •í•¨ì„ ê°€ì •í•œë‹¤. ë”°ë¼ì„œ, ë„ë©”ì¸ì— ë”°ë¼ Ordinal Encodingì„ ë³€í˜•í•´ì•¼ í•  ìˆ˜ë„ ìˆë‹¤.

```python
import pandas as pd
from sklearn.preprocessing import OrdinalEncoder

# ì˜ˆì‹œ ë°ì´í„°í”„ë ˆì„ ìƒì„±
data = pd.DataFrame({'category': ['A', 'B', 'C', 'B', 'A', 'C']})

# OrdinalEncoder ê°ì²´ ìƒì„±
encoder = OrdinalEncoder()

# ë²”ì£¼í˜• ë³€ìˆ˜ì— ëŒ€í•´ Ordinal Encoding ìˆ˜í–‰
data_encoded = encoder.fit_transform(data[['category']])

# ì¸ì½”ë”©ëœ ë°ì´í„°ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ê¸°ì¡´ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
data['category_encoded'] = data_encoded

# ê²°ê³¼ í™•ì¸
print(data)
```